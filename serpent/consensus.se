# extern pca: [emwpca]
# PCA = create("emwpca.se")

# Arithmetic mean of an array
macro mean($a:$asz):
    with total = 0:
        with i = 0:
            while i < $asz:
                total += $a[i]
                i += 1
        total * 0x10000000000000000 / i

# Dot (inner) product of vectors.
macro dot($a, $b, $len):
    with i = 0:
        with prod = 0:
            while i < $len:
                prod += $a[i] * $b[i]
                i += 1
            prod

# Sum elements of array
macro sum($a:$asz):
    with total = 0:
        with i = 0:
            while i < $asz:
                total += $a[i]
                i += 1
        total

# Normalize array (elements sum to 1)
macro normalize($a:$asz):
    with anorm = array($asz):
        with total = 0:
            with i = 0:
                while i < $asz:
                    if $a[i] != None:
                        total += $a[i]
                    i += 1
            with i = 0:
                while i < $asz:
                    if $a[i] != None:
                        anorm[i] = $a[i] * 0x10000000000000000 / total
                    i += 1
            anorm

# Calculates the outer product of vectors.
macro outer_product($u:$usz, $v:$vsz):
    with p = array($usz):
        with i = 0:
            while i < $usz:
                p[i] = array($usz)
                with j = 0:
                    while j < $usz:
                        p[i][j] += $u[i] * $v[j]
                        j += 1
                i += 1
            p

# Vector Kronecker product
macro kron($a:$asz, $b:$bsz):
    with prod = array($asz * $bsz):
        with i = 0:
            while i < $asz:
                with j = 0:
                    while j < $bsz:
                        prod[j + $bsz*i] = $a[i] * $b[j]
                        j += 1
                i += 1
        prod

# Matrix multiplication, inputs are flattened (vectorized) matrices
macro multiply($aflat:$asz, $arows, $acols, $bflat:$bsz, $brows, $bcols):
    with a = array($arows):
        with i = 0:
            while i < $arows:
                a[i] = array($acols)
                with j = 0:
                    while j < $acols:
                        a[i][j] = $aflat[j + i*$acols]
                        j += 1
                i += 1
        with b = array($brows):
            with i = 0:
                while i < $brows:
                    b[i] = array($bcols)
                    with j = 0:
                        while j < $bcols:
                            b[i][j] = $bflat[j + i*$bcols]
                            j += 1
                    i += 1
            with c = array($arows):
                if $bcols > 1:
                    with i = 0:
                        while i < $arows:
                            c[i] = array($bcols)
                            i += 1
                with i = 0:
                    while i < $arows:
                        with j = 0:
                            while j < $bcols:
                                with k = 0:
                                    while k < $acols:
                                        if $bcols == 1:
                                            c[i] += a[i][k] * b[k]
                                        else:
                                            c[i][j] += a[i][k] * b[k][j]
                                        k += 1
                                j += 1
                        i += 1
                c

# Swap the rows and columns of a matrix
macro transpose($aflat:$asz, $arows, $acols):
    with a = array($arows):
        with i = 0:
            while i < $arows:
                a[i] = array($acols)
                with j = 0:
                    while j < $acols:
                        a[i][j] = $aflat[j + i*$acols]
                        j += 1
                i += 1
        with at = array($acols):
            with i = 0:
                while i < $asz:
                    at[i] = array($arows)
                    i += 1
            with i = 0:
                while i < $acols:
                    with j = 0:
                        while j < $arows:
                            at[i][j] = a[j][i]
                            j += 1
                    i += 1
            at

# Convert vector to diagonal matrix
macro diag($a:$asz):
    with d = array($asz):
        with i = 0:
            while i < $asz:
                d[i] = array($asz)
                with j = 0:
                    while j < $asz:
                        if i == j:
                            d[i][j] = $a[i]
                        else:
                            d[i][j] = 0
                        j += 1
                i += 1
        d

# Missing entries marked with -1
macro isnan($a:$asz):
    with amask = array($asz):
        with i = 0:
            while i < $asz:
                if $a[i] == -1:
                    amask[i] = 1
                else:
                    amask[i] = 0
                i += 1
            amask

macro mask($a:$asz, $target):
    with amask = array($asz):
        with i = 0:
            while i < $asz:
                if $a[i] == $target:
                    amask[i] = 1
                else:
                    amask[i] = 0
                i += 1
            amask

macro any($a:$asz):
    with result = 0:
        with i = 0: 
            while i < $asz:
                if $a[i] != 0:
                    result = 1
                    break
                i += 1
            result

# Hadamard (elementwise) product, inputs are flattened (vectorized) matrices
macro hadamard($aflat:$asz, $arows, $acols, $bflat:$bsz, $brows, $bcols):
    with a = array($arows):
        with i = 0:
            while i < $arows:
                a[i] = array($acols)
                with j = 0:
                    while j < $acols:
                        a[i][j] = $aflat[j + i*$acols]
                        j += 1
                i += 1
        with b = array($brows):
            with i = 0:
                while i < $brows:
                    b[i] = array($bcols)
                    with j = 0:
                        while j < $bcols:
                            b[i][j] = $bflat[j + i*$bcols]
                            j += 1
                    i += 1
            with c = array($arows):
                if $bcols > 1:
                    with i = 0:
                        while i < $bcols:
                            c[i] = array($bcols)
                            i += 1
                with i = 0:
                    while i < $arows:
                        if $bcols == 1 and $acols == 1:
                            c[i] = a[i] * b[i]
                        else:
                            with j = 0:
                                while j < $bcols:
                                    c[i][j] += a[i][j] * b[i][j]
                                    j += 1
                        i += 1
                c

# Proportional distances from zero
macro get_weight($a:$asz):
    with total = 0:
        with i = 0:
            while i < $asz:
                total += $a[i]
                i += 1
    with total = 0:
        with i = 0:
            while i < $asz:
                total += $a[i]
                i += 1
        with i = 0:
            with b = array($asz):
                while i < $asz:
                    b[i] = $a[i] * 0x10000000000000000 / total
                i += 1
            b

# Bins values to 0, .5, and 1
macro catch($x):
    with catch_lo = (0x10000000000000000 - 0x1999999999999999) / 2:
        with catch_hi = (0x10000000000000000 + 0x1999999999999999) / 2:
            if $x < catch_lo:
                caught = 0x0
            elif $x > catch_hi:
                caught = 0x10000000000000000
            else:
                caught = 0x8000000000000000
            caught

# Absolute value
macro abs($x):
    with absval = $x:
        if $x < 0:
            absval = -$x
        absval

# Minimum value of array
macro minimum($a:$asz):
    with minval = $a[0]:
        with i = 1:
            while i < $asz:
                if $a[i] < minval:
                    minval = $a[i]
                i += 1
        minval

# Maximum value of array
macro maximum($a:$asz):
    with maxval = $a[0]:
        with i = 1:
            while i < $asz:
                if $a[i] > maxval:
                    maxval = $a[i]
                i += 1
        maxval

def consensus(votes:a, reputation:a):
    startgas = tx.gas
    num_voters = arglen(reputation)
    v_size = arglen(votes)
    num_events = v_size / num_voters

    # use exisiting data and reputations to fill missing observations
    # (weighted average using all non-missing data)
    votes_mask = array(v_size)
    missing_values = 0
    with i = 0:
        while i < v_size:
            if votes[i] == -0x10000000000000000:
                votes_mask[i] = 1
                missing_values += 1
            else:
                votes_mask[i] = 0
            i += 1

    if missing_values:
        # votes_filled = array(num_voters)
        votes_filled = array(v_size)
        outcomes_raw = array(num_events)
        j = 0
        while j < num_events:

            # reputation of the users who voted, rescaled to sum to 1
            total_active_rep = 0
            i = 0
            while i < num_voters:
                if votes[i*num_events + j] != -1:
                    total_active_rep += reputation[i]
                i += 1

            # normalize
            active_players_rep = array(num_voters)
            i = 0
            while i < num_voters:
                if votes[i*num_events + j] != -1:
                    active_players_rep[i] = reputation[i] / total_active_rep
                else:
                    # set missing values to 0
                    active_players_rep[i] = 0
                i += 1

            # current event with missing entries removed
            active_events = array(num_voters)
            i = 0
            while i < num_voters:
                if votes[i*num_events + j] != -1:
                    active_events[i] = votes[i*num_events + j]
                else:
                    active_events[i] = 0
                i += 1

            # current best-guess for this event's outcome is a weighted sum
            # (votes weighted by reputation)
            i = 0
            outcomes_raw[j] = 0
            while i < num_voters:
                outcomes_raw[j] += active_players_rep[i] * active_events[i] / 0x10000000000000000
                i += 1
            
            j += 1

        i = 0
        while i < v_size:
            if votes[i] == -1:
                votes_filled[i] = 0
            else:
                votes_filled[i] = votes[i]
            i += 1

        diag_outcomes = diag(outcomes_raw:num_events)

        to_fill = array(v_size)
        while i < num_voters:
            j = 0
            while j < num_events:
                k = 0
                while k < num_events:
                    pos = i*num_events + j
                    to_fill[pos] += votes_mask[i*num_events + k] * diag_outcomes[k][j]
                    k += 1
                votes_filled[pos] += catch(to_fill[pos])
                j += 1
            i += 1

    else:
        votes_filled = votes

    # weighted pca: project votes onto principal component
    weighted_means = array(num_events)
    total_weight = 0
    i = 0
    while i < num_voters:
        j = 0
        while j < num_events:
            weighted_means[j] += reputation[i] * votes_filled[i * num_events + j]
            j += 1
        total_weight += reputation[i]
        i += 1

    j = 0
    while j < num_events:
        weighted_means[j] /= total_weight
        j += 1

    weighted_centered_data = array(v_size)
    i = 0
    while i < v_size:
        weighted_centered_data[i] = votes_filled[i] - weighted_means[i % num_events]
        i += 1

    # initialize the loading vector
    loading_vector = array(num_events)
    loading_vector[0] = 0x10000000000000000

    i = 0
    # careful, setting this to 25 causes tx gas to run out!
    while i < 15:
        s = array(num_events)
        j = 0
        while j < num_voters:
            d_dot_lv = 0
            k = 0
            while k < num_events:
                d_dot_lv += weighted_centered_data[j * num_events + k] * loading_vector[k]
                k += 1
            d_dot_lv /= 0x10000000000000000
            k = 0
            while k < num_events:
                s[k] -= d_dot_lv * weighted_centered_data[j * num_events + k] * reputation[j]
                k += 1
            j += 1
        # loading_vector = normalize(s)
        # (first rejig s to account for double fixed multiplication in loop)
        j = 0
        while j < num_events:
            s[j] /= 0x100000000000000000000000000000000
            j += 1
        # QQ
        s_dot_s = 0
        j = 0
        while j < num_events:
            s_dot_s += s[j] * s[j]
            j += 1
        s_dot_s /= 0x10000000000000000
        # QQ!!!!
        norm_s = s_dot_s / 2
        j = 0
        while j < 11:
            norm_s = (norm_s + s_dot_s*0x10000000000000000/norm_s) / 2
            j += 1
        # fuggin assign
        j = 0
        while j < num_events:
            loading_vector[j] = s[j]*0x10000000000000000/norm_s
            j += 1

        i += 1

    # return(votes, v_size)
    # return(votes_filled, v_size)
    # return(reputation, num_voters)
    # return(votes_mask, v_size)    
    # return(loading_vector, num_events)

    scores = array(num_voters)
    i = 0
    while i < num_voters:
        k = 0
        while k < num_events:
            scores[i] += weighted_centered_data[i*num_events + k] * loading_vector[k] / 0x10000000000000000
            k += 1
        i += 1

    # return(scores, num_voters)
    # return(weighted_centered_data, v_size)

    # Which of the two possible 'new' reputation vectors had more opinion in common
    # with the original 'old' reputation.
    # set1 = scores + abs(min(scores))
    # set2 = scores - max(scores)
    # old = multiply(transpose(self.reputation), votes_filled)
    # new1 = multiply(get_weight(set1), votes_filled)
    # new2 = multiply(get_weight(set2), votes_filled)

    set1 = array(num_voters)
    set2 = array(num_voters)
    i = 0
    while i < num_voters:
        set1[i] = scores[i] + abs(minimum(scores:num_voters))
        set2[i] = scores[i] - maximum(scores:num_voters)
        i += 1

    return([startgas, tx.gas], 2)

    # # Difference in sum of squared errors. If > 0, then new1 had higher
    # # errors (use new2); conversely if < 0, then use new1.
    # ref_ind = sum((new1 - old)^2) - sum((new2 - old)^2)
    # if ref_ind <= 0:
    #     adj_prin_comp = set1
    # if ref_ind > 0:
    #     adj_prin_comp = set2
  
    # # Set this to uniform if you want a passive diffusion toward equality
    # # when people cooperate.  Instead diffuses towards previous reputation.
    # # (Smoothing does this anyway!)
    # row_reward_weighted = self.reputation
    # if max(abs(adj_prin_comp)) != 0:
    #     # Overwrite the inital declaration IFF there wasn't perfect consensus.
    #     row_reward_weighted = get_weight(adj_prin_comp * transpose(self.reputation / self.mean(self.reputation)))

    # # Freshly-Calculated Reward (Reputation) - Exponential Smoothing
    # # New Reward: row_reward_weighted
    # # Old Reward: reputation
    # smooth_rep = ALPHA*row_reward_weighted + (1 - ALPHA)*transpose(self.reputation)

    # outcomes_raw = multiply(smooth_rep, votes_filled)
    # outcome_final = array(num_events)
    # i = 0
    # while i < num_events:
    #     outcome_final[i] = catch(outcomes_raw[i])
    #     i += 1

    # # .5 is obviously undesireable, this function travels from 0 to 1
    # # with a minimum at .5
    # certainty = abs(2 * (outcomes_raw - 0.5))
    # # Grading Authors on a curve.
    # consensus_reward = get_weight(certainty)
    # # How well did beliefs converge?
    # avg_certainty = self.mean(certainty)

    # # Participation: information about missing values
    # na_mat = self.votes * 0
    # na_mat_mask = mask(na_mat)
    # na_mat[na_mat_mask] = 1  # missing-value indicator matrix
    # # Participation within events (columns)
    # participation_columns = 1 - multiply(smooth_rep, na_mat)
    # # Participation within agents (Rows)
    # participation_rows = 1 - na_mat.sum(axis=1) / na_mat.shape[1]
    # # General participation
    # percent_na = 1 - mean(participation_columns)

    # # Combine information
    # na_bonus_rows = get_weight(participation_rows)
    # row_bonus = na_bonus_rows * percent_na + smooth_rep * (1 - percent_na)
    # na_bonus_columns = get_weight(participation_columns)
    # col_bonus = na_bonus_columns * percent_na + consensus_reward * (1 - percent_na)

    # return(row_bonus, num_voters)
